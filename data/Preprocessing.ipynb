{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d0e596",
   "metadata": {},
   "source": [
    "## Deep Classification Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73c8da",
   "metadata": {},
   "source": [
    "0. First, the grid established in the Dataset exploration notebook will be tested with the SVM. Then, a DNN is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df51ce6",
   "metadata": {},
   "source": [
    "1. Import all `modules` we are going to need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb6c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff6ab38",
   "metadata": {},
   "source": [
    "2. Set up y. Then, import and process X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c2d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf50ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/kosti/mat2csv/emotic_pre/')\n",
    "train = pd.read_csv('train.csv')\n",
    "train_mscoco = train[train['Folder'] == 'mscoco/images']\n",
    "train_frames = train[train['Folder'] == 'framesdb/images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f5937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a3b6e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "y_fr = []\n",
    "for rating_ms in train_mscoco['Continuous_Labels']:\n",
    "    y.append(rating_ms)\n",
    "\n",
    "for rating_frames in train_frames['Continuous_Labels']: \n",
    "    y.append(rating_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30ada82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21624"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "455ca006",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = []\n",
    "for idx, label in enumerate(y):\n",
    "    s = (re.sub(r\"[\\[\\]]\",'',y[idx]))\n",
    "    for i, x in enumerate(s):\n",
    "        y_.append(x)\n",
    "        if x == ',':\n",
    "            y_.remove(x)\n",
    "        if x == ' ':\n",
    "            y_.remove(x)\n",
    "        try:\n",
    "            if x == '1' and s[i+1] == '0':\n",
    "                y_.remove(x)\n",
    "                y_.append('10')\n",
    "        except IndexError:\n",
    "            continue\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ba2e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, el in enumerate(y_):\n",
    "    if el == '10':\n",
    "        if y_[idx+1] == '0':\n",
    "            y_.remove(y_[idx+1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9ba188c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64872"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58173aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_labels = []\n",
    "for val in y_:\n",
    "    cont_labels.append(float(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82f6da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 0\n",
    "Arousal = []\n",
    "Valence = []\n",
    "Dominance = []\n",
    "for val in cont_labels:\n",
    "    if img == 0:\n",
    "        Arousal.append(val)\n",
    "        img = img+1\n",
    "        continue\n",
    "    if img == 1:\n",
    "        Valence.append(val)\n",
    "        img = img+1\n",
    "        continue \n",
    "    if img == 2:\n",
    "        Dominance.append(val)\n",
    "        img = 0\n",
    "        continue\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f69f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Arousal = np.array(Arousal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3780b4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21624,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Arousal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30082995",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31ef8e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a56a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_select = SelectKBest(k=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a096c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75542407",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.to_csv('Arousal_frames_emodb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c383dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21619</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21620</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21621</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21622</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21623</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21624 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0      5.0\n",
       "1      6.0\n",
       "2      7.0\n",
       "3      8.0\n",
       "4      7.0\n",
       "...    ...\n",
       "21619  6.0\n",
       "21620  5.0\n",
       "21621  5.0\n",
       "21622  6.0\n",
       "21623  5.0\n",
       "\n",
       "[21624 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "314e7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_series = y_df.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d77096a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000    7.0\n",
       "12001    6.0\n",
       "12002    5.0\n",
       "12003    6.0\n",
       "12004    8.0\n",
       "        ... \n",
       "14271    5.0\n",
       "14272    8.0\n",
       "14273    2.0\n",
       "14274    6.0\n",
       "14275    7.0\n",
       "Name: 0, Length: 2276, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_series[12000:14276]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1a82bf",
   "metadata": {},
   "source": [
    "**NEXT STEP**:\n",
    "\n",
    "`Rename`all columns more meaningful. Then apply k-best to all chunked dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1188f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48955dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...\n",
      "Read the 0 dataframe\n",
      "Read the 1 dataframe\n",
      "Read the 2 dataframe\n",
      "Read the 3 dataframe\n",
      "Read the 4 dataframe\n"
     ]
    }
   ],
   "source": [
    "# the number of row in each data frame\n",
    "# you can put any value here according to your situation\n",
    "chunksize = 5000\n",
    "# the list that contains all the dataframes\n",
    "list_of_dataframes = []\n",
    "\n",
    "print('processing...')\n",
    "for index, df in enumerate(pd.read_csv('X_Matrix.csv', chunksize=chunksize)):\n",
    "    # process your data frame here\n",
    "    # then add the current data frame into the list\n",
    "    list_of_dataframes.append(df)\n",
    "    print('Read the {num} dataframe'.format(num=index))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4565231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...\n",
      "Read the 0 dataframe\n",
      "Read the 1 dataframe\n",
      "Read the 2 dataframe\n",
      "Read the 3 dataframe\n"
     ]
    }
   ],
   "source": [
    "# the number of row in each data frame\n",
    "# you can put any value here according to your situation\n",
    "chunksize = 2000\n",
    "\n",
    "print('processing...')\n",
    "for index, df in enumerate(pd.read_csv('X_frames.csv', chunksize=chunksize)):\n",
    "    # process your data frame here\n",
    "    # then add the current data frame into the list\n",
    "    list_of_dataframes.append(df)\n",
    "    print('Read the {num} dataframe'.format(num=index))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8ad4adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5752ae1f",
   "metadata": {},
   "source": [
    "**TESTING IF REGULAR SGD WORKS ON ALL FEATURES WITH 21 K SAMPLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6332c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff90109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c08634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "542bc953",
   "metadata": {},
   "outputs": [],
   "source": [
    "Log = SGDClassifier(loss='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a1ea13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_dataframes[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e9d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "j=3000\n",
    "c_initial=0\n",
    "for chunk, df in enumerate(list_of_dataframes):\n",
    "    X = scaler.fit_transform(df)\n",
    "    print('Partial fitting the model...')\n",
    "    Log.partial_fit(X,y[c_initial:df.shape[0]], classes = np.unique(y))\n",
    "    if chunk == 7:\n",
    "        c_initial = list_of_dataframes[i].shape[0]\n",
    "        X_pred_prob = Log.score(X,y[c_initial:df.shape[0]])\n",
    "        print('The accuracy for the training set is {prob}'.format(prob=X_pred_prob))\n",
    "        break\n",
    "    else:\n",
    "        del X\n",
    "        c_initial = list_of_dataframes[i].shape[0]\n",
    "        i=i+1\n",
    "        j=j+df.shape[0]\n",
    "        print('Will now continue with chunk {chunk}'.format(chunk=chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff4534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1e16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ab25936",
   "metadata": {},
   "source": [
    "**TESTING END**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76093b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in list_of_dataframes:\n",
    "    for pos, col in enumerate(df):\n",
    "        df.columns.values[pos] = 'Feature ' + str(pos)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89b423d1",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpauli/miniconda3/envs/yolo/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied k-best to 0/5 chunks!\n",
      "processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpauli/miniconda3/envs/yolo/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied k-best to 1/5 chunks!\n",
      "processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpauli/miniconda3/envs/yolo/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied k-best to 2/5 chunks!\n",
      "processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpauli/miniconda3/envs/yolo/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied k-best to 3/5 chunks!\n",
      "processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpauli/miniconda3/envs/yolo/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied k-best to 4/5 chunks!\n"
     ]
    }
   ],
   "source": [
    "k_list = []\n",
    "track = 0\n",
    "i=0\n",
    "j=3000\n",
    "for chunk in list_of_dataframes:\n",
    "    print('processing...')\n",
    "    k_select.fit_transform(chunk, y_df[i:j])\n",
    "    cols_idxs = k_select.get_support(indices=True)\n",
    "    k_list.append(chunk.iloc[:,cols_idxs])\n",
    "    print('Applied k-best to {track}/5 chunks!'.format(track=track))\n",
    "    track=track+1\n",
    "    if track == 4:\n",
    "        i=12000\n",
    "        j=12000+list_of_dataframes[4].shape[0]\n",
    "        \n",
    "    else:\n",
    "        i=i+3000\n",
    "        j=j+3000\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d264f8",
   "metadata": {},
   "source": [
    "**Step 4.**\n",
    "\n",
    "`Majority voting`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c503cc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25390"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(k_list[0]).intersection(k_list[1], k_list[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb6be888",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(k_list[0]).intersection(k_list[1], k_list[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be3fa2",
   "metadata": {},
   "source": [
    "**Step 5.**\n",
    "\n",
    "Reduce columns from *k* (=40000) to the amount of features that are commmon between dataframe one, two and three.\n",
    "\n",
    "Then concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80d45908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing chunk 0/2\n",
      "processing chunk 1/2\n",
      "processing chunk 2/2\n"
     ]
    }
   ],
   "source": [
    "feature_list = []\n",
    "for chunk, df in enumerate(list_of_dataframes):\n",
    "    print('processing chunk {chunk}/2'.format(chunk=chunk))\n",
    "    feature_list.append(df[features])\n",
    "    if chunk == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83e42c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_0\n",
      "df_1\n",
      "df_2\n"
     ]
    }
   ],
   "source": [
    "for chunk, df in enumerate(feature_list):\n",
    "    print('df_{cunk}'.format(cunk=chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c96e38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list[0].to_csv('X_1.csv')\n",
    "feature_list[1].to_csv('X_2.csv')\n",
    "feature_list[2].to_csv('X_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc530e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining dataframes for RAM purposes\n",
    "list_df_r = []\n",
    "list_df_r.append(list_of_dataframes[3])\n",
    "list_df_r.append(list_of_dataframes[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab5c4d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing chunk 0/1\n",
      "processing chunk 1/1\n"
     ]
    }
   ],
   "source": [
    "for pos, df in enumerate(list_df_r):\n",
    "    print('processing chunk {pos}/1'.format(pos=pos))\n",
    "    feature_list.append(df[features])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd185fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list[3].to_csv('X_4.csv')\n",
    "feature_list[4].to_csv('X_5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLO",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
