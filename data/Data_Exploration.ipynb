{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b142c5e",
   "metadata": {},
   "source": [
    "## **0. Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04761262",
   "metadata": {},
   "source": [
    "This notebook serves the purpose of exploring the data used in the master thesis. For now I will look into the dataset from [Kosti et al., 2017](https://openaccess.thecvf.com/content_cvpr_2017/papers/Kosti_Emotion_Recognition_in_CVPR_2017_paper.pdf), the data can be requested [here](https://docs.google.com/forms/d/e/1FAIpQLScXwxhEZu7RpHwgiRqVfb09GzHSSyIm64hJQMgHSLm75ltsFQ/viewform).\n",
    "\n",
    "There are different types of image folders. At first I will investigate the \"emodb_small\" folder. This contains mostly images, in which the face is clearly visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01ee0cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/kosti/emodb_small/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4575aaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d0dc4",
   "metadata": {},
   "source": [
    "The emod_small folder contains 861 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beedc619",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "The annotations are stored in a *struct* within a *.mat* file. There exists a pytorch implementation, that stores .py file which transform the mat files into csv files. Please follow [this link](https://github.com/Tandon-A/emotic) to the respective github repository. After I assembled the images and annotations in the demanded structure, I ran the mat2py file and ended up with a training, validation and test csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95bfbea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/kosti/mat2csv/emotic_pre/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dde6a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv', 'train.csv', 'val.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e6f146",
   "metadata": {},
   "source": [
    "We will now inspect the 'train.csv' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8586c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2b0d50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data consists of 23266 images.\n"
     ]
    }
   ],
   "source": [
    "print('The training data consists of {} images.'.format(train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "208b349a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Image Size</th>\n",
       "      <th>BBox</th>\n",
       "      <th>Categorical_Labels</th>\n",
       "      <th>Continuous_Labels</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mscoco/images</td>\n",
       "      <td>COCO_val2014_000000562243.jpg</td>\n",
       "      <td>[640, 640]</td>\n",
       "      <td>[86, 58, 564, 628]</td>\n",
       "      <td>['Disconnection', 'Doubt/Confusion']</td>\n",
       "      <td>[5, 3, 9]</td>\n",
       "      <td>Male</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mscoco/images</td>\n",
       "      <td>COCO_train2014_000000288841.jpg</td>\n",
       "      <td>[640, 480]</td>\n",
       "      <td>[485, 149, 605, 473]</td>\n",
       "      <td>['Anticipation']</td>\n",
       "      <td>[6, 4, 7]</td>\n",
       "      <td>Male</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mscoco/images</td>\n",
       "      <td>COCO_val2014_000000558171.jpg</td>\n",
       "      <td>[640, 480]</td>\n",
       "      <td>[305, 92, 461, 465]</td>\n",
       "      <td>['Engagement', 'Excitement', 'Happiness']</td>\n",
       "      <td>[7, 8, 8]</td>\n",
       "      <td>Male</td>\n",
       "      <td>Teenager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mscoco/images</td>\n",
       "      <td>COCO_train2014_000000369575.jpg</td>\n",
       "      <td>[480, 640]</td>\n",
       "      <td>[221, 63, 448, 372]</td>\n",
       "      <td>['Aversion', 'Pleasure']</td>\n",
       "      <td>[8, 9, 8]</td>\n",
       "      <td>Male</td>\n",
       "      <td>Kid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mscoco/images</td>\n",
       "      <td>COCO_train2014_000000213009.jpg</td>\n",
       "      <td>[500, 333]</td>\n",
       "      <td>[44, 143, 150, 288]</td>\n",
       "      <td>['Confidence', 'Excitement']</td>\n",
       "      <td>[7, 9, 10]</td>\n",
       "      <td>Male</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>mscoco/images</td>\n",
       "      <td>COCO_train2014_000000462955.jpg</td>\n",
       "      <td>[640, 478]</td>\n",
       "      <td>[42, 32, 413, 472]</td>\n",
       "      <td>['Anticipation', 'Engagement', 'Peace']</td>\n",
       "      <td>[3, 6, 8]</td>\n",
       "      <td>Male</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>mscoco/images</td>\n",
       "      <td>COCO_val2014_000000168683.jpg</td>\n",
       "      <td>[500, 375]</td>\n",
       "      <td>[257, 39, 405, 183]</td>\n",
       "      <td>['Anticipation', 'Engagement']</td>\n",
       "      <td>[6, 7, 7]</td>\n",
       "      <td>Male</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>mscoco/images</td>\n",
       "      <td>COCO_train2014_000000186198.jpg</td>\n",
       "      <td>[640, 429]</td>\n",
       "      <td>[336, 80, 494, 327]</td>\n",
       "      <td>['Anticipation', 'Peace']</td>\n",
       "      <td>[7, 7, 8]</td>\n",
       "      <td>Male</td>\n",
       "      <td>Kid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>mscoco/images</td>\n",
       "      <td>COCO_train2014_000000006590.jpg</td>\n",
       "      <td>[640, 480]</td>\n",
       "      <td>[188, 109, 381, 382]</td>\n",
       "      <td>['Engagement']</td>\n",
       "      <td>[7, 4, 7]</td>\n",
       "      <td>Female</td>\n",
       "      <td>Kid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>mscoco/images</td>\n",
       "      <td>COCO_train2014_000000144608.jpg</td>\n",
       "      <td>[350, 500]</td>\n",
       "      <td>[198, 29, 300, 232]</td>\n",
       "      <td>['Fatigue', 'Happiness']</td>\n",
       "      <td>[7, 7, 6]</td>\n",
       "      <td>Male</td>\n",
       "      <td>Teenager</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index         Folder                         Filename  Image Size  \\\n",
       "0      0  mscoco/images    COCO_val2014_000000562243.jpg  [640, 640]   \n",
       "1      1  mscoco/images  COCO_train2014_000000288841.jpg  [640, 480]   \n",
       "2      2  mscoco/images    COCO_val2014_000000558171.jpg  [640, 480]   \n",
       "3      3  mscoco/images  COCO_train2014_000000369575.jpg  [480, 640]   \n",
       "4      4  mscoco/images  COCO_train2014_000000213009.jpg  [500, 333]   \n",
       "5      5  mscoco/images  COCO_train2014_000000462955.jpg  [640, 478]   \n",
       "6      6  mscoco/images    COCO_val2014_000000168683.jpg  [500, 375]   \n",
       "7      7  mscoco/images  COCO_train2014_000000186198.jpg  [640, 429]   \n",
       "8      8  mscoco/images  COCO_train2014_000000006590.jpg  [640, 480]   \n",
       "9      9  mscoco/images  COCO_train2014_000000144608.jpg  [350, 500]   \n",
       "\n",
       "                   BBox                         Categorical_Labels  \\\n",
       "0    [86, 58, 564, 628]       ['Disconnection', 'Doubt/Confusion']   \n",
       "1  [485, 149, 605, 473]                           ['Anticipation']   \n",
       "2   [305, 92, 461, 465]  ['Engagement', 'Excitement', 'Happiness']   \n",
       "3   [221, 63, 448, 372]                   ['Aversion', 'Pleasure']   \n",
       "4   [44, 143, 150, 288]               ['Confidence', 'Excitement']   \n",
       "5    [42, 32, 413, 472]    ['Anticipation', 'Engagement', 'Peace']   \n",
       "6   [257, 39, 405, 183]             ['Anticipation', 'Engagement']   \n",
       "7   [336, 80, 494, 327]                  ['Anticipation', 'Peace']   \n",
       "8  [188, 109, 381, 382]                             ['Engagement']   \n",
       "9   [198, 29, 300, 232]                   ['Fatigue', 'Happiness']   \n",
       "\n",
       "  Continuous_Labels  Gender       Age  \n",
       "0         [5, 3, 9]    Male     Adult  \n",
       "1         [6, 4, 7]    Male     Adult  \n",
       "2         [7, 8, 8]    Male  Teenager  \n",
       "3         [8, 9, 8]    Male       Kid  \n",
       "4        [7, 9, 10]    Male     Adult  \n",
       "5         [3, 6, 8]    Male     Adult  \n",
       "6         [6, 7, 7]    Male     Adult  \n",
       "7         [7, 7, 8]    Male       Kid  \n",
       "8         [7, 4, 7]  Female       Kid  \n",
       "9         [7, 7, 6]    Male  Teenager  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d23f2d2",
   "metadata": {},
   "source": [
    "We see that the training set not only contains the continous and categorial labels, but the respective image. Since we may want to take adavantage of the different image type for each \"folder\", we could extract the respective folder with the labels. Meaning we have 4 csv files for each folder type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "418be616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mscoco/images', 'emodb_small/images', 'framesdb/images',\n",
       "       'ade20k/images'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Folder'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro_ai",
   "language": "python",
   "name": "neuro_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
