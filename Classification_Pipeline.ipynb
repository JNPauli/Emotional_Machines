{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JNPauli/Protect_app_master_thesis/blob/main/Classification_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3485813",
      "metadata": {
        "id": "f3485813"
      },
      "source": [
        "0. This notebook is the continuation to the preprocessing.ipynb notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b60fcc27",
      "metadata": {
        "id": "b60fcc27"
      },
      "source": [
        "1. Import all neccessary modules "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "73af1d9d",
      "metadata": {
        "id": "73af1d9d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwWpOPN-SkYk",
        "outputId": "45cb951a-9bb7-4973-ce6d-bd050265fea2"
      },
      "id": "xwWpOPN-SkYk",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bab0d03",
      "metadata": {
        "id": "0bab0d03"
      },
      "source": [
        "2. Import X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0e61570a",
      "metadata": {
        "id": "0e61570a"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Thesis')"
      ],
      "metadata": {
        "id": "Q822x4HZTzzr"
      },
      "id": "Q822x4HZTzzr",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "99428f03",
      "metadata": {
        "id": "99428f03"
      },
      "outputs": [],
      "source": [
        "y = np.load('train_con.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "986e4ca0",
      "metadata": {
        "id": "986e4ca0"
      },
      "outputs": [],
      "source": [
        "y_ = y[0:10000]\n",
        "y_frames = y[14276:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_all = np.concatenate((y_,y_frames))"
      ],
      "metadata": {
        "id": "hkGr-adRJKPY"
      },
      "id": "hkGr-adRJKPY",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "daf7012a",
      "metadata": {
        "id": "daf7012a"
      },
      "source": [
        "NEW APPROACH:\n",
        "\n",
        "Fit CNN on X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fdc2364",
      "metadata": {
        "id": "4fdc2364"
      },
      "source": [
        "1. Read `n-rows`from X."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r367TL-IeTgB",
        "outputId": "0ace8128-f7cb-46df-b4cd-ffca153d80c6"
      },
      "id": "r367TL-IeTgB",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "27e2352f",
      "metadata": {
        "id": "27e2352f"
      },
      "outputs": [],
      "source": [
        "X = np.load('X_npy.npy')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_,X_test_,y_train_,y_test_ = train_test_split(X,y_,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "PsyUuoBPLir0"
      },
      "id": "PsyUuoBPLir0",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del X,y_\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKWPUYNJJPA6",
        "outputId": "d1914b42-2ce4-4f63-ca51-5d3ba0d969b8"
      },
      "id": "eKWPUYNJJPA6",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_, X_val_, y_train_, y_val_ = train_test_split(X_train_,y_train_, test_size = 0.2,random_state=42)"
      ],
      "metadata": {
        "id": "dr2axO3gX8gV"
      },
      "id": "dr2axO3gX8gV",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_frames = np.load('frames_npy.npy')"
      ],
      "metadata": {
        "id": "m6MUfvXMLxdU"
      },
      "id": "m6MUfvXMLxdU",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_f,X_test_f,y_train_f,y_test_f = train_test_split(X_frames,y_frames,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "Eokk-SMBLyv1"
      },
      "id": "Eokk-SMBLyv1",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del X_frames,y_frames\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4rrcEI-L7lO",
        "outputId": "1592ed2c-10bf-4f17-c359-9af731ee00bf"
      },
      "id": "g4rrcEI-L7lO",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_f, X_val_f, y_train_f, y_val_f = train_test_split(X_train_f,y_train_f, test_size = 0.2,random_state=42)"
      ],
      "metadata": {
        "id": "J0CTpvPgzB9e"
      },
      "id": "J0CTpvPgzB9e",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "43fc4d4d",
      "metadata": {
        "id": "43fc4d4d"
      },
      "source": [
        "Converting X to appropriate Datatype..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "95e21cb9",
      "metadata": {
        "id": "95e21cb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3858df-1e42-4bf4-85c5-e11d68634930"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X_tensor_train = torch.from_numpy(X_train_)\n",
        "del X_train_\n",
        "gc.collect()\n",
        "X_tensor_test = torch.from_numpy(X_test_)\n",
        "del X_test_\n",
        "gc.collect()\n",
        "X_tensor_val = torch.from_numpy(X_val_)\n",
        "del X_val_\n",
        "gc.collect()\n",
        "\n",
        "y_tensor_train = torch.from_numpy(y_train_)\n",
        "del y_train_\n",
        "gc.collect()\n",
        "y_tensor_test = torch.from_numpy(y_test_)\n",
        "del y_test_\n",
        "gc.collect()\n",
        "y_tensor_val = torch.from_numpy(y_val_)\n",
        "del y_val_\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "83ce427f",
      "metadata": {
        "id": "83ce427f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d95bc2-1c75-40cb-9eb8-21d0f960a1eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-3ff54277ee2f>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_tensor_train = torch.tensor(X_tensor_train,dtype = torch.float32)\n",
            "<ipython-input-18-3ff54277ee2f>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_tensor_test = torch.tensor(X_tensor_test,dtype = torch.float32)\n",
            "<ipython-input-18-3ff54277ee2f>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_tensor_val = torch.tensor(X_tensor_val,dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "X_tensor_train = torch.tensor(X_tensor_train,dtype = torch.float32)\n",
        "X_tensor_test = torch.tensor(X_tensor_test,dtype = torch.float32)\n",
        "X_tensor_val = torch.tensor(X_tensor_val,dtype=torch.float32)\n",
        "\n",
        "y_tensor_train = y_tensor_train.type(torch.LongTensor)\n",
        "y_tensor_test = y_tensor_test.type(torch.LongTensor)\n",
        "y_tensor_val = y_tensor_val.type(torch.LongTensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82e920b8",
      "metadata": {
        "id": "82e920b8"
      },
      "source": [
        "Pytorch needs the true labels to be in the range N-1. Thus, substract 1 one from each label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fe7f344c",
      "metadata": {
        "id": "fe7f344c"
      },
      "outputs": [],
      "source": [
        "y_tensor_train = y_tensor_train-1\n",
        "y_tensor_test = y_tensor_test-1\n",
        "y_tensor_val = y_tensor_val-1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor_train_ = torch.from_numpy(X_train_f)\n",
        "del X_train_f\n",
        "gc.collect()\n",
        "X_tensor_test_ = torch.from_numpy(X_test_f)\n",
        "del X_test_f\n",
        "gc.collect()\n",
        "X_tensor_val_ = torch.from_numpy(X_val_f)\n",
        "del X_val_f\n",
        "gc.collect()\n",
        "\n",
        "y_tensor_train_ = torch.from_numpy(y_train_f)\n",
        "del y_train_f\n",
        "gc.collect()\n",
        "y_tensor_test_ = torch.from_numpy(y_test_f)\n",
        "del y_test_f\n",
        "gc.collect()\n",
        "y_tensor_val_ = torch.from_numpy(y_val_f)\n",
        "del y_val_f\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axPSV66iP70K",
        "outputId": "313718ea-60f5-4393-db04-aebaf4502d92"
      },
      "id": "axPSV66iP70K",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor_train_ = torch.tensor(X_tensor_train_,dtype = torch.float32)\n",
        "X_tensor_test_ = torch.tensor(X_tensor_test_,dtype = torch.float32)\n",
        "X_tensor_val = torch.tensor(X_tensor_val_,dtype=torch.float32)\n",
        "\n",
        "y_tensor_train_ = y_tensor_train_.type(torch.LongTensor)\n",
        "y_tensor_test_ = y_tensor_test_.type(torch.LongTensor)\n",
        "y_tensor_val = y_tensor_val_.type(torch.LongTensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu02Y4zGP721",
        "outputId": "2c09f450-6fb4-4637-9e38-7010bcf2381f"
      },
      "id": "cu02Y4zGP721",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-daeb6c2c99f4>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_tensor_train_ = torch.tensor(X_tensor_train_,dtype = torch.float32)\n",
            "<ipython-input-21-daeb6c2c99f4>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_tensor_test_ = torch.tensor(X_tensor_test_,dtype = torch.float32)\n",
            "<ipython-input-21-daeb6c2c99f4>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_tensor_val = torch.tensor(X_tensor_val_,dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_tensor_train_ = y_tensor_train_-1\n",
        "y_tensor_test_ = y_tensor_test_-1\n",
        "y_tensor_val_ = y_tensor_val_-1"
      ],
      "metadata": {
        "id": "l2619kh5Qsvh"
      },
      "id": "l2619kh5Qsvh",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor_train = torch.cat((X_tensor_train,X_tensor_train_),0)\n",
        "X_tensor_test = torch.cat((X_tensor_test,X_tensor_test_),0)\n",
        "X_tensor_val = torch.cat((X_tensor_val, X_tensor_val_),0)\n",
        "\n",
        "y_tensor_train = torch.cat((y_tensor_train,y_tensor_train_),0)\n",
        "y_tensor_test = torch.cat((y_tensor_test,y_tensor_test_),0)\n",
        "y_tensor_val = torch.cat((y_tensor_val,y_tensor_val_),0)"
      ],
      "metadata": {
        "id": "6YgbQB1WP8Gb"
      },
      "id": "6YgbQB1WP8Gb",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('training shape X is {}, validation shape is {}, test shape X is{}'.format(X_tensor_train.shape,X_tensor_val.shape,X_tensor_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3CAcuLCulnT",
        "outputId": "14dc7ba3-1e3d-4a41-ec2e-33d240c22341"
      },
      "id": "w3CAcuLCulnT",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training shape X is torch.Size([11102, 1, 224, 224]), validation shape is torch.Size([2352, 1, 224, 224]), test shape X istorch.Size([3470, 1, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5379ae48",
      "metadata": {
        "id": "5379ae48"
      },
      "source": [
        "Setup custom dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "76e13d73",
      "metadata": {
        "id": "76e13d73"
      },
      "outputs": [],
      "source": [
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        X = self.X[idx]\n",
        "        y = self.y[idx]\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "af6a5a92",
      "metadata": {
        "id": "af6a5a92"
      },
      "outputs": [],
      "source": [
        "dataset_train = SimpleDataset(X_tensor_train,y_tensor_train)\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
        "\n",
        "dataset_val = SimpleDataset(X_tensor_val,y_tensor_val)\n",
        "dataloader_val = DataLoader(dataset_val,batch_size=32)\n",
        "\n",
        "dataset_test = SimpleDataset(X_tensor_test,y_tensor_test)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size = 32)#,shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c4df5ea",
      "metadata": {
        "id": "9c4df5ea"
      },
      "source": [
        "Setting up the CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c5b23ab6",
      "metadata": {
        "id": "c5b23ab6"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.dropout2 = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(774400, 128)\n",
        "        self.fc2 = nn.Linear(128, 3)#,10\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "#removed "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ad94c3ad",
      "metadata": {
        "id": "ad94c3ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072d7b26-959b-4699-8f94-51d470754f70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (dropout1): Dropout(p=0.5, inplace=False)\n",
              "  (dropout2): Dropout(p=0.25, inplace=False)\n",
              "  (fc1): Linear(in_features=774400, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "SalienceNet = CNN()\n",
        "SalienceNet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ContinuousLoss_L2(nn.Module):\n",
        "  ''' Class to measure loss between continuous emotion dimension predictions and labels. Using l2 loss as base. '''\n",
        "  def __init__(self, margin=1):\n",
        "    super(ContinuousLoss_L2, self).__init__()\n",
        "    self.margin = margin\n",
        "  \n",
        "  def forward(self, pred, target):\n",
        "    labs = torch.abs(pred - target)\n",
        "    loss = labs ** 2 \n",
        "    loss[ (labs < self.margin) ] = 0.0\n",
        "    return loss.sum()"
      ],
      "metadata": {
        "id": "bSEPAmQoJlkq"
      },
      "id": "bSEPAmQoJlkq",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont_loss = ContinuousLoss_L2()"
      ],
      "metadata": {
        "id": "wpriQW4-Johz"
      },
      "id": "wpriQW4-Johz",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "eMAlEzRt0VTw"
      },
      "id": "eMAlEzRt0VTw",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "9997283d",
      "metadata": {
        "id": "9997283d"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(net, loss_fn, dataloader_train,dataloader_val,\n",
        "          epoch=100, learning_rate=0.0001):\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate,weight_decay=1e-4) # weight decay as a regularization technique to defy overfitting\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    train_epoch_loss = []\n",
        "    val_epoch_loss = []\n",
        "    for i in range(epoch):\n",
        "        train_loop = tqdm(dataloader_train)\n",
        "        val_loop = tqdm(dataloader_val)\n",
        "        total,correct = 0,0\n",
        "        net.to(device)   \n",
        "        net.train()\n",
        "        for data, label in train_loop:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "        #make prediction\n",
        "            output = net(data.float())\n",
        "\n",
        "            _, y_pred_train = torch.max(output,1) # get predicted train label\n",
        "\n",
        "            # Zero out the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Calculate loss.\n",
        "            #loss = loss_fn(output,torch.max(label.long(), 1)[0])\n",
        "            loss = loss_fn(output*10,label*10)\n",
        "\n",
        "            # Backpropagation and gradient update.\n",
        "            loss.backward()# Calculate gradients. #retrain_graph=True\n",
        "\n",
        "            optimizer.step() # Apply gradient udpate.\n",
        "\n",
        "            #total += label.size(0)\n",
        "            #correct += (y_pred_train == torch.max(label,1)[0]).sum().item()\n",
        "            \n",
        "            train_loss.append(loss.item())\n",
        "            train_loop.set_description(f\"Epoch [{i}/{epoch}]\")\n",
        "        \n",
        "        train_epoch_loss.append((np.array(train_loss).mean()))\n",
        "        net.eval()\n",
        "        val_total,val_correct = 0,0\n",
        "        val_acc = []\n",
        "        for data, labels in dataloader_val:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            outputs = net(data.float())\n",
        "\n",
        "            _, y_pred_val = torch.max(outputs,1) # get predicted label for test\n",
        "\n",
        "            \n",
        "            #test_l = loss_fn(outputs,torch.max(labels.long(), 1)[0])\n",
        "            val_l = loss_fn(outputs*10,labels*10)\n",
        "            val_loss.append(val_l.item())\n",
        "\n",
        "        val_epoch_loss.append((np.array(val_loss).mean()))\n",
        "\n",
        "\n",
        "    return train_loss,train_epoch_loss,val_loss,val_epoch_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(net,loss_fn,dataloader_test):\n",
        "  net.eval()\n",
        "  test_loss = []\n",
        "  test_total,test_correct = 0,0\n",
        "  test_acc = []\n",
        "  for data, labels in dataloader_test:\n",
        "      print('testing...')\n",
        "\n",
        "      data, labels = data.to(device), labels.to(device)\n",
        "      outputs = net(data.float())\n",
        "\n",
        "      _, y_pred_test = torch.max(outputs,1) # get predicted label for test\n",
        "\n",
        "        \n",
        "      #test_l = loss_fn(outputs,torch.max(labels.long(), 1)[0])\n",
        "      test_l = loss_fn(outputs*10,labels*10)\n",
        "      test_loss.append(test_l.item())\n",
        "\n",
        "        #test_total += labels.size(0)\n",
        "        #test_correct += (y_pred_test==torch.max(labels,1)[0]).sum().item()\n",
        "        \n",
        "    #test_acc.append(test_correct/test_total)\n",
        "    #y_pred_test = torch.softmax(outputs,dim=1).argmax(dim=1)\n",
        "\n",
        "   # print('test acc is {}'.format(test_acc)\n",
        "  return test_loss"
      ],
      "metadata": {
        "id": "JvEWX6FyZGIk"
      },
      "id": "JvEWX6FyZGIk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "yDqIlocyWRYY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72107202-a86f-4da8-ebdf-e34d9353a11f"
      },
      "id": "yDqIlocyWRYY",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "7e318c98",
      "metadata": {
        "id": "7e318c98"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript\n",
        "\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})''')) "
      ],
      "metadata": {
        "id": "kGxhNDnUbZMD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "23677634-6385-41fe-8faa-a037618827d8"
      },
      "id": "kGxhNDnUbZMD",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5ddd06d",
      "metadata": {
        "id": "c5ddd06d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5eee1e-9600-4c00-b264-d8a8385dec40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/347 [00:00<?, ?it/s]\n",
            "Epoch [0/10]:  57%|█████▋    | 197/347 [00:26<00:20,  7.45it/s]"
          ]
        }
      ],
      "source": [
        "np.random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "\n",
        "train_loss,train_epoch_loss,val_loss,val_epoch_loss=train(net=SalienceNet,loss_fn=cont_loss,dataloader_train=dataloader_train,\n",
        "                  dataloader_val=dataloader_val,epoch=10)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_epoch_loss, label = 'train loss')\n",
        "plt.plot(val_epoch_loss, label = 'validation loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('L2 Loss')\n",
        "plt.title('L2 loss per epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fk-6haR7G5-q"
      },
      "id": "fk-6haR7G5-q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f6R0T3jZ_9H",
        "outputId": "60309b11-a3f2-48c5-a5b0-8138ff37d60d"
      },
      "id": "7f6R0T3jZ_9H",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37565.18359375,\n",
              " 53586.53125,\n",
              " 28303.67578125,\n",
              " 35039.44921875,\n",
              " 40455.72265625,\n",
              " 25226.185546875,\n",
              " 35791.046875,\n",
              " 23188.65625,\n",
              " 49315.32421875,\n",
              " 28502.87109375,\n",
              " 47693.59375,\n",
              " 32145.6484375,\n",
              " 23170.40234375,\n",
              " 31613.087890625,\n",
              " 26943.1171875,\n",
              " 21932.494140625,\n",
              " 29918.140625,\n",
              " 34458.1328125,\n",
              " 37175.9609375,\n",
              " 25998.337890625,\n",
              " 49661.15625,\n",
              " 29237.58984375,\n",
              " 46846.8125,\n",
              " 31324.12890625,\n",
              " 31369.087890625,\n",
              " 27329.26953125,\n",
              " 25935.53125,\n",
              " 26298.623046875,\n",
              " 23326.921875,\n",
              " 30491.857421875,\n",
              " 24849.7421875,\n",
              " 28984.197265625,\n",
              " 23546.94921875,\n",
              " 23136.5234375,\n",
              " 28846.97265625,\n",
              " 34998.4296875,\n",
              " 26828.490234375,\n",
              " 22482.529296875,\n",
              " 21667.4296875,\n",
              " 25360.875,\n",
              " 34901.484375,\n",
              " 30876.759765625,\n",
              " 19847.9296875,\n",
              " 29188.94921875,\n",
              " 26812.927734375,\n",
              " 28620.03125,\n",
              " 21213.67578125,\n",
              " 28936.94921875,\n",
              " 32485.65625,\n",
              " 34737.15234375,\n",
              " 24934.75,\n",
              " 26069.48828125,\n",
              " 23148.62890625,\n",
              " 22050.0703125,\n",
              " 29807.076171875,\n",
              " 26958.7890625,\n",
              " 23135.67578125,\n",
              " 21250.34375,\n",
              " 28408.25390625,\n",
              " 27289.47265625,\n",
              " 22043.33984375,\n",
              " 25998.939453125,\n",
              " 31307.263671875,\n",
              " 26028.482421875,\n",
              " 26997.15625,\n",
              " 19424.44140625,\n",
              " 28432.51171875,\n",
              " 27869.79296875,\n",
              " 29746.3125,\n",
              " 29901.92578125,\n",
              " 27487.5625,\n",
              " 27797.6328125,\n",
              " 25083.39453125,\n",
              " 24305.73828125,\n",
              " 30363.888671875,\n",
              " 20983.7734375,\n",
              " 25299.482421875,\n",
              " 23615.517578125,\n",
              " 22558.904296875,\n",
              " 24988.01171875,\n",
              " 32901.046875,\n",
              " 14129.642578125,\n",
              " 24738.935546875,\n",
              " 19633.873046875,\n",
              " 24491.1640625,\n",
              " 25659.50390625,\n",
              " 18506.22265625,\n",
              " 21068.17578125,\n",
              " 33296.3125,\n",
              " 31711.67578125,\n",
              " 27868.2421875,\n",
              " 31744.35546875,\n",
              " 22651.126953125,\n",
              " 20729.736328125,\n",
              " 30656.40234375,\n",
              " 32292.05078125,\n",
              " 30883.5234375,\n",
              " 21794.712890625,\n",
              " 23130.54296875,\n",
              " 39975.05859375,\n",
              " 28449.6953125,\n",
              " 39566.9375,\n",
              " 31227.21875,\n",
              " 22641.62109375,\n",
              " 35140.64453125,\n",
              " 33592.1015625,\n",
              " 23082.8359375,\n",
              " 27470.2734375,\n",
              " 26917.05859375,\n",
              " 34111.33203125,\n",
              " 35334.765625,\n",
              " 35350.9765625,\n",
              " 20882.85546875,\n",
              " 27615.111328125,\n",
              " 30488.90234375,\n",
              " 44697.9765625,\n",
              " 25823.826171875,\n",
              " 27721.060546875,\n",
              " 22338.25390625,\n",
              " 31359.4921875,\n",
              " 25871.6171875,\n",
              " 34976.01171875,\n",
              " 29276.31640625,\n",
              " 33533.33203125,\n",
              " 31198.6875,\n",
              " 31424.095703125,\n",
              " 30023.85546875,\n",
              " 16072.140625,\n",
              " 27307.091796875,\n",
              " 30091.640625,\n",
              " 28970.263671875,\n",
              " 23795.474609375,\n",
              " 23670.1328125,\n",
              " 26027.05078125,\n",
              " 23951.32421875,\n",
              " 23784.369140625,\n",
              " 35751.52734375,\n",
              " 32512.443359375,\n",
              " 18089.7734375,\n",
              " 19408.375,\n",
              " 24939.32421875,\n",
              " 22401.08203125,\n",
              " 25762.990234375,\n",
              " 35264.5390625,\n",
              " 40145.08984375,\n",
              " 28477.0546875,\n",
              " 20330.09375,\n",
              " 24632.27734375,\n",
              " 23404.501953125,\n",
              " 29213.76953125,\n",
              " 18661.21484375,\n",
              " 21768.708984375,\n",
              " 21311.845703125,\n",
              " 24606.8203125,\n",
              " 25359.890625,\n",
              " 34905.1171875,\n",
              " 23522.56640625,\n",
              " 24603.169921875,\n",
              " 22417.828125,\n",
              " 28791.359375,\n",
              " 31957.525390625,\n",
              " 28734.712890625,\n",
              " 31312.658203125,\n",
              " 29445.85546875,\n",
              " 26740.466796875,\n",
              " 22440.09375,\n",
              " 28111.42578125,\n",
              " 31099.458984375,\n",
              " 25263.6484375,\n",
              " 31826.615234375,\n",
              " 24327.95703125,\n",
              " 21411.24609375,\n",
              " 30551.77734375,\n",
              " 23001.08984375,\n",
              " 25966.80078125,\n",
              " 24167.10546875,\n",
              " 24245.07421875,\n",
              " 19125.57421875,\n",
              " 24670.154296875,\n",
              " 23091.857421875,\n",
              " 20067.857421875,\n",
              " 23353.353515625,\n",
              " 32266.28515625,\n",
              " 27345.490234375,\n",
              " 24865.41796875,\n",
              " 27043.6640625,\n",
              " 21950.828125,\n",
              " 29740.982421875,\n",
              " 27034.572265625,\n",
              " 22559.77734375,\n",
              " 28571.88671875,\n",
              " 28931.94921875,\n",
              " 29196.5234375,\n",
              " 30458.890625,\n",
              " 23327.89453125,\n",
              " 28216.333984375,\n",
              " 24525.7421875,\n",
              " 31489.83203125,\n",
              " 17032.158203125,\n",
              " 23610.796875,\n",
              " 32858.41015625,\n",
              " 35429.59765625,\n",
              " 32646.3671875,\n",
              " 21783.353515625,\n",
              " 24085.05078125,\n",
              " 37645.36328125,\n",
              " 42835.546875,\n",
              " 31868.61328125,\n",
              " 23800.189453125,\n",
              " 30484.24609375,\n",
              " 38960.234375,\n",
              " 42702.86328125,\n",
              " 25481.779296875,\n",
              " 25560.966796875,\n",
              " 38916.6875,\n",
              " 43546.33984375,\n",
              " 48266.0859375,\n",
              " 31480.771484375,\n",
              " 22102.015625,\n",
              " 40327.76953125,\n",
              " 37560.1953125,\n",
              " 38166.25390625,\n",
              " 22300.560546875,\n",
              " 23841.63671875,\n",
              " 43570.6875,\n",
              " 34772.6484375,\n",
              " 32285.390625,\n",
              " 27303.765625,\n",
              " 24902.30859375,\n",
              " 21994.171875,\n",
              " 29916.42578125,\n",
              " 25836.876953125,\n",
              " 21189.98046875,\n",
              " 21045.89453125,\n",
              " 22623.853515625,\n",
              " 29526.3359375,\n",
              " 22477.98828125,\n",
              " 26633.32421875,\n",
              " 41673.51953125,\n",
              " 24761.615234375,\n",
              " 28633.8515625,\n",
              " 33527.21875,\n",
              " 21311.2421875,\n",
              " 24753.41796875,\n",
              " 28193.484375,\n",
              " 26003.78125,\n",
              " 27790.94140625,\n",
              " 22774.45703125,\n",
              " 24300.5078125,\n",
              " 26070.3125,\n",
              " 27908.703125,\n",
              " 26932.064453125,\n",
              " 22401.544921875,\n",
              " 33366.046875,\n",
              " 31024.24609375,\n",
              " 32199.140625,\n",
              " 29869.53125,\n",
              " 25434.96875,\n",
              " 24398.31640625,\n",
              " 25154.095703125,\n",
              " 28310.296875,\n",
              " 25913.474609375,\n",
              " 26688.978515625,\n",
              " 33858.0078125,\n",
              " 28047.41015625,\n",
              " 16729.8046875,\n",
              " 20959.818359375,\n",
              " 19811.69140625,\n",
              " 28847.673828125,\n",
              " 27996.6171875,\n",
              " 23775.93359375,\n",
              " 25537.12109375,\n",
              " 24430.46875,\n",
              " 20527.51171875,\n",
              " 26634.517578125,\n",
              " 20457.578125,\n",
              " 25052.859375,\n",
              " 18648.73828125,\n",
              " 18539.869140625,\n",
              " 26376.49609375,\n",
              " 26202.193359375,\n",
              " 20979.7578125,\n",
              " 21960.484375,\n",
              " 18418.1015625,\n",
              " 22288.32421875,\n",
              " 30454.21484375,\n",
              " 21792.05859375,\n",
              " 29590.8515625,\n",
              " 24280.501953125,\n",
              " 25680.40625,\n",
              " 25270.546875,\n",
              " 28867.029296875,\n",
              " 17939.359375,\n",
              " 17297.806640625,\n",
              " 24499.21484375,\n",
              " 24600.734375,\n",
              " 31992.892578125,\n",
              " 26357.94921875,\n",
              " 22991.20703125,\n",
              " 32074.1953125,\n",
              " 22328.17578125,\n",
              " 27460.50390625,\n",
              " 28494.7578125,\n",
              " 26367.556640625,\n",
              " 23678.7734375,\n",
              " 23447.27734375,\n",
              " 19683.90234375,\n",
              " 25037.94140625,\n",
              " 22072.892578125,\n",
              " 21362.69140625,\n",
              " 25779.44921875,\n",
              " 19329.32421875,\n",
              " 21989.43359375,\n",
              " 34738.33984375,\n",
              " 30440.8203125,\n",
              " 23179.056640625,\n",
              " 25065.017578125,\n",
              " 20956.484375,\n",
              " 26325.328125,\n",
              " 22996.099609375,\n",
              " 22199.826171875,\n",
              " 30537.96875,\n",
              " 28522.556640625,\n",
              " 31552.796875,\n",
              " 25621.322265625,\n",
              " 28711.88671875,\n",
              " 25933.716796875,\n",
              " 32262.46875,\n",
              " 24459.90625,\n",
              " 29676.828125,\n",
              " 29002.38671875,\n",
              " 26102.373046875,\n",
              " 23505.990234375,\n",
              " 21835.34375,\n",
              " 34385.109375,\n",
              " 31389.607421875,\n",
              " 26316.8828125,\n",
              " 26248.314453125,\n",
              " 25231.712890625,\n",
              " 26631.935546875,\n",
              " 32961.4765625,\n",
              " 41727.984375,\n",
              " 20877.123046875,\n",
              " 27516.6328125,\n",
              " 38231.68359375,\n",
              " 35331.78125,\n",
              " 25489.46484375,\n",
              " 22531.60546875,\n",
              " 20894.49609375,\n",
              " 26047.98046875,\n",
              " 24073.625,\n",
              " 20642.017578125,\n",
              " 21431.521484375,\n",
              " 22867.40234375,\n",
              " 29033.6796875,\n",
              " 24871.7109375,\n",
              " 31481.791015625,\n",
              " 23084.568359375,\n",
              " 19868.173828125,\n",
              " 30086.755859375,\n",
              " 24484.79296875,\n",
              " 25458.8359375,\n",
              " 26561.0625,\n",
              " 29270.7265625,\n",
              " 27272.6640625,\n",
              " 23416.609375,\n",
              " 19042.90234375,\n",
              " 22461.06640625,\n",
              " 23254.890625,\n",
              " 21072.98828125,\n",
              " 25401.921875,\n",
              " 19343.5703125,\n",
              " 23041.26953125,\n",
              " 24866.546875,\n",
              " 21674.912109375,\n",
              " 23821.25390625,\n",
              " 26342.70703125,\n",
              " 25115.779296875,\n",
              " 24089.251953125,\n",
              " 27440.60546875,\n",
              " 27699.2578125,\n",
              " 22805.322265625,\n",
              " 30651.921875,\n",
              " 31412.115234375,\n",
              " 28775.865234375,\n",
              " 33141.828125,\n",
              " 30192.09375,\n",
              " 31410.83203125,\n",
              " 33263.296875,\n",
              " 34844.1328125,\n",
              " 25331.1640625,\n",
              " 39982.765625,\n",
              " 28781.84765625,\n",
              " 40908.4375,\n",
              " 40677.53125,\n",
              " 39426.1015625,\n",
              " 28196.93359375,\n",
              " 31182.236328125,\n",
              " 27383.462890625,\n",
              " 35063.80859375,\n",
              " 33770.37109375,\n",
              " 40305.234375,\n",
              " 31504.177734375,\n",
              " 29787.375,\n",
              " 28615.0703125,\n",
              " 43932.796875,\n",
              " 32773.140625,\n",
              " 27119.650390625,\n",
              " 24014.0546875,\n",
              " 39261.765625,\n",
              " 31111.41015625,\n",
              " 37733.16015625,\n",
              " 32464.31640625,\n",
              " 34142.5234375,\n",
              " 29930.33984375,\n",
              " 24880.521484375,\n",
              " 42595.5703125,\n",
              " 33075.15625,\n",
              " 36145.55859375,\n",
              " 30390.888671875,\n",
              " 25473.470703125,\n",
              " 38724.4921875,\n",
              " 25053.1171875,\n",
              " 39210.3046875,\n",
              " 39700.34375,\n",
              " 37420.30859375,\n",
              " 34592.1328125,\n",
              " 28819.2265625,\n",
              " 33854.36328125,\n",
              " 32820.97265625,\n",
              " 32843.10546875,\n",
              " 33367.1171875,\n",
              " 31530.9453125,\n",
              " 28032.134765625,\n",
              " 39021.953125,\n",
              " 28367.51953125,\n",
              " 29114.3359375,\n",
              " 29685.330078125,\n",
              " 28779.0546875,\n",
              " 33328.44921875,\n",
              " 26171.404296875,\n",
              " 46506.796875,\n",
              " 35560.8203125,\n",
              " 30264.029296875,\n",
              " 35661.2109375,\n",
              " 36108.3984375,\n",
              " 32866.03125,\n",
              " 30309.65234375,\n",
              " 30529.443359375,\n",
              " 31089.720703125,\n",
              " 23958.1484375,\n",
              " 31817.67578125,\n",
              " 28138.65234375,\n",
              " 40620.4140625,\n",
              " 43357.078125,\n",
              " 20917.853515625,\n",
              " 27558.07421875,\n",
              " 32771.4140625,\n",
              " 30695.375,\n",
              " 29701.7421875,\n",
              " 33802.71484375,\n",
              " 32271.44140625,\n",
              " 32153.705078125,\n",
              " 27976.8125,\n",
              " 30690.779296875,\n",
              " 29483.1796875,\n",
              " 30164.2109375,\n",
              " 27159.9609375,\n",
              " 25727.80859375,\n",
              " 35584.73828125,\n",
              " 34236.453125,\n",
              " 32898.11328125,\n",
              " 27030.59375,\n",
              " 32732.7109375,\n",
              " 30748.798828125,\n",
              " 31989.40234375,\n",
              " 28555.759765625,\n",
              " 31477.19921875,\n",
              " 30389.701171875,\n",
              " 35451.8359375,\n",
              " 23443.826171875,\n",
              " 25704.01171875,\n",
              " 34933.59375,\n",
              " 38354.0,\n",
              " 28188.91015625,\n",
              " 31653.27734375,\n",
              " 28326.681640625,\n",
              " 24663.44140625,\n",
              " 28776.630859375,\n",
              " 29354.9921875,\n",
              " 24727.0703125,\n",
              " 31685.6328125,\n",
              " 24871.875,\n",
              " 27489.458984375,\n",
              " 26315.455078125,\n",
              " 35357.1484375,\n",
              " 22240.0,\n",
              " 30570.16796875,\n",
              " 36942.2265625,\n",
              " 35393.7578125,\n",
              " 28766.3984375,\n",
              " 27191.203125,\n",
              " 31730.25,\n",
              " 31271.953125,\n",
              " 39456.8984375,\n",
              " 35297.0703125,\n",
              " 31885.8046875,\n",
              " 32369.853515625,\n",
              " 33257.5078125,\n",
              " 30170.54296875,\n",
              " 30476.908203125,\n",
              " 29947.16015625,\n",
              " 22508.2421875,\n",
              " 27217.5234375,\n",
              " 31191.173828125,\n",
              " 27650.134765625,\n",
              " 22512.302734375,\n",
              " 31487.248046875,\n",
              " 30256.556640625,\n",
              " 33535.25390625,\n",
              " 39029.53515625,\n",
              " 35364.50390625,\n",
              " 32129.33984375,\n",
              " 40177.47265625,\n",
              " 38657.99609375,\n",
              " 23911.4296875,\n",
              " 32934.53125,\n",
              " 26705.7734375,\n",
              " 23113.9921875,\n",
              " 36681.171875,\n",
              " 34979.7109375,\n",
              " 28659.408203125,\n",
              " 27355.37109375,\n",
              " 33108.484375,\n",
              " 36862.19140625,\n",
              " 26575.89453125,\n",
              " 32799.3203125,\n",
              " 35216.0703125,\n",
              " 32254.80859375,\n",
              " 36817.17578125,\n",
              " 30537.189453125,\n",
              " 25492.0,\n",
              " 37190.40234375,\n",
              " 42079.57421875,\n",
              " 32058.05078125,\n",
              " 29230.05859375,\n",
              " 36506.07421875,\n",
              " 37252.6953125,\n",
              " 29093.89453125,\n",
              " 34052.06640625,\n",
              " 29335.39453125,\n",
              " 31444.5703125,\n",
              " 33493.97265625,\n",
              " 31477.875,\n",
              " 38950.25,\n",
              " 28209.43359375,\n",
              " 29356.8671875,\n",
              " 26444.09765625,\n",
              " 37955.390625,\n",
              " 31947.24609375,\n",
              " 31660.96484375,\n",
              " 23556.73828125,\n",
              " 27153.90234375,\n",
              " 27380.0703125,\n",
              " 27138.287109375,\n",
              " 28486.60546875,\n",
              " 32493.796875,\n",
              " 31136.3671875,\n",
              " 32235.5703125,\n",
              " 18869.27734375,\n",
              " 35132.94140625,\n",
              " 26794.212890625,\n",
              " 33422.875,\n",
              " 30309.869140625,\n",
              " 24868.654296875,\n",
              " 34081.95703125,\n",
              " 28371.142578125,\n",
              " 27607.640625,\n",
              " 38746.15625,\n",
              " 26935.501953125,\n",
              " 42865.07421875,\n",
              " 38007.58203125,\n",
              " 32179.11328125,\n",
              " 30686.205078125,\n",
              " 39188.515625,\n",
              " 35762.703125,\n",
              " 28128.759765625,\n",
              " 21910.67578125,\n",
              " 35618.01953125,\n",
              " 27318.97265625,\n",
              " 48620.39453125,\n",
              " 29772.9296875,\n",
              " 35083.671875,\n",
              " 32306.228515625,\n",
              " 29577.328125,\n",
              " 34584.10546875,\n",
              " 34203.4765625,\n",
              " 37561.2421875,\n",
              " 29842.66796875,\n",
              " 30712.9453125,\n",
              " 33335.71484375,\n",
              " 38664.28515625,\n",
              " 28160.455078125,\n",
              " 26265.40625,\n",
              " 27014.62109375,\n",
              " 30443.07421875,\n",
              " 24526.765625,\n",
              " 29625.00390625,\n",
              " 25062.86328125,\n",
              " 27774.2421875,\n",
              " 29503.447265625,\n",
              " 30181.9921875,\n",
              " 27905.845703125,\n",
              " 27214.1171875,\n",
              " 24089.484375,\n",
              " 25593.52734375,\n",
              " 22029.05859375,\n",
              " 33899.23828125,\n",
              " 31276.732421875,\n",
              " 34637.51171875,\n",
              " 23778.578125,\n",
              " 28586.20703125,\n",
              " 26701.73046875,\n",
              " 33197.5703125,\n",
              " 26596.98828125,\n",
              " 29794.169921875,\n",
              " 24622.466796875,\n",
              " 29702.240234375,\n",
              " 26719.203125,\n",
              " 36183.5234375,\n",
              " 35953.69921875,\n",
              " 31518.90234375,\n",
              " 23183.88671875,\n",
              " 28993.455078125,\n",
              " 31748.361328125,\n",
              " 35512.03125,\n",
              " 26471.44921875,\n",
              " 32632.3046875,\n",
              " 22856.046875,\n",
              " 37917.078125,\n",
              " 36783.57421875,\n",
              " 29503.275390625,\n",
              " 29958.48828125,\n",
              " 29068.7109375,\n",
              " 23841.17578125,\n",
              " 32769.75390625,\n",
              " 34248.5390625,\n",
              " 36347.8125,\n",
              " 35915.34375,\n",
              " 27077.7890625,\n",
              " 33387.83203125,\n",
              " 33510.67578125,\n",
              " 23272.80859375,\n",
              " 29228.001953125,\n",
              " 42569.3671875,\n",
              " 34423.20703125,\n",
              " 31255.830078125,\n",
              " 33469.3125,\n",
              " 29966.3515625,\n",
              " 26443.14453125,\n",
              " 28492.5859375,\n",
              " 27271.951171875,\n",
              " 39621.8671875,\n",
              " 30454.416015625,\n",
              " 25257.1875,\n",
              " 33834.41015625,\n",
              " 33531.890625,\n",
              " 30338.91015625,\n",
              " 37834.59765625,\n",
              " 36876.1171875,\n",
              " 30860.00390625,\n",
              " 21306.978515625,\n",
              " 28721.66015625,\n",
              " 23365.1484375,\n",
              " 25947.349609375,\n",
              " 24068.97265625,\n",
              " 28801.5859375,\n",
              " 23094.037109375,\n",
              " 29123.0234375,\n",
              " 34747.21484375,\n",
              " 38943.4296875,\n",
              " 30429.49609375,\n",
              " 30109.68359375,\n",
              " 30712.087890625,\n",
              " 30772.84375,\n",
              " 35088.09375,\n",
              " 29260.87890625,\n",
              " 31151.435546875,\n",
              " 30573.328125,\n",
              " 27557.421875,\n",
              " 32951.2890625,\n",
              " 22860.673828125,\n",
              " 32416.6328125,\n",
              " 39988.578125,\n",
              " 31898.349609375,\n",
              " 30275.263671875,\n",
              " 25849.55859375,\n",
              " 32766.875,\n",
              " 29877.837890625,\n",
              " 28751.57421875,\n",
              " 30295.533203125,\n",
              " 29944.23046875,\n",
              " 24951.373046875,\n",
              " 33586.890625,\n",
              " 40083.8984375,\n",
              " 29584.353515625,\n",
              " 29365.373046875,\n",
              " 25958.685546875,\n",
              " 23707.76953125,\n",
              " 20571.21484375,\n",
              " 30556.98046875,\n",
              " 36254.1640625,\n",
              " 30051.34375,\n",
              " 28278.451171875,\n",
              " 34458.6796875,\n",
              " 29229.15625,\n",
              " 27115.169921875,\n",
              " 33141.8359375,\n",
              " 37883.0234375,\n",
              " 36497.91015625,\n",
              " 20633.234375,\n",
              " 22206.0703125,\n",
              " 24229.1953125,\n",
              " 31153.619140625,\n",
              " 23794.00390625,\n",
              " 27691.55859375,\n",
              " 30315.51171875,\n",
              " 21300.345703125,\n",
              " 31045.5078125,\n",
              " 32243.95703125,\n",
              " 20610.3984375,\n",
              " 27328.638671875,\n",
              " 30595.876953125,\n",
              " 30200.42578125,\n",
              " 25312.64453125,\n",
              " 28663.01171875,\n",
              " 20858.837890625,\n",
              " 35064.3515625,\n",
              " 28461.1484375,\n",
              " 26104.994140625,\n",
              " 25241.93359375,\n",
              " 20522.04296875,\n",
              " 24495.625,\n",
              " 23384.755859375,\n",
              " 25479.84765625,\n",
              " 28093.0625,\n",
              " 27978.876953125,\n",
              " 25423.53125,\n",
              " 24629.794921875,\n",
              " 16308.744140625,\n",
              " 33966.1484375,\n",
              " 30128.58984375,\n",
              " 28762.1796875,\n",
              " 26217.53515625,\n",
              " 30049.173828125,\n",
              " 19647.78125,\n",
              " 28691.62109375,\n",
              " 26975.6328125,\n",
              " 24415.728515625,\n",
              " 25745.2734375,\n",
              " 28485.30859375,\n",
              " 22497.390625,\n",
              " 17875.744140625,\n",
              " 25645.25,\n",
              " 31348.75,\n",
              " 25827.564453125,\n",
              " 28142.3046875,\n",
              " 21628.744140625,\n",
              " 27744.583984375,\n",
              " 32429.580078125,\n",
              " 29246.474609375,\n",
              " 22417.84375,\n",
              " 28275.087890625,\n",
              " 21702.83984375,\n",
              " 34225.0078125,\n",
              " 35596.8515625,\n",
              " 28195.380859375,\n",
              " 32477.744140625,\n",
              " 22008.681640625,\n",
              " 27502.154296875,\n",
              " 20992.033203125,\n",
              " 28407.72265625,\n",
              " 26800.435546875,\n",
              " 25255.244140625,\n",
              " 30891.3984375,\n",
              " 27445.39453125,\n",
              " 26401.18359375,\n",
              " 27238.759765625,\n",
              " 29137.92578125,\n",
              " 24228.1484375,\n",
              " 32221.19140625,\n",
              " 24945.5859375,\n",
              " 31542.61328125,\n",
              " 31644.5546875,\n",
              " 28710.4296875,\n",
              " 24685.203125,\n",
              " 27312.423828125,\n",
              " 33043.234375,\n",
              " 21507.38671875,\n",
              " 33240.37109375,\n",
              " 34597.5390625,\n",
              " 28655.92578125,\n",
              " 29602.328125,\n",
              " 25151.7734375,\n",
              " 33703.84375,\n",
              " 28673.4140625,\n",
              " 32130.37890625,\n",
              " 27303.150390625,\n",
              " 37484.35546875,\n",
              " 34106.23828125,\n",
              " 27911.61328125,\n",
              " 27146.9296875,\n",
              " 25358.078125,\n",
              " 28455.91015625,\n",
              " 25710.86328125,\n",
              " 28903.4296875,\n",
              " 32795.7421875,\n",
              " 24984.142578125,\n",
              " 34373.15625,\n",
              " 26356.203125,\n",
              " 30997.7578125,\n",
              " 29251.576171875,\n",
              " 28227.3125,\n",
              " 20891.8125,\n",
              " 34818.99609375,\n",
              " 28648.8984375,\n",
              " 32376.05078125,\n",
              " 30530.962890625,\n",
              " 28037.54296875,\n",
              " 39648.78125,\n",
              " 21232.681640625,\n",
              " 30283.4296875,\n",
              " 27922.80859375,\n",
              " 20943.66015625,\n",
              " 34645.59765625,\n",
              " 34056.765625,\n",
              " 27037.82421875,\n",
              " 33865.4296875,\n",
              " 28071.595703125,\n",
              " 31262.63671875,\n",
              " 27822.67578125,\n",
              " 21563.33203125,\n",
              " 28420.591796875,\n",
              " 26123.5703125,\n",
              " 29352.26953125,\n",
              " 31855.3203125,\n",
              " 31966.435546875,\n",
              " 27674.265625,\n",
              " 26899.65234375,\n",
              " 28318.076171875,\n",
              " 28168.578125,\n",
              " 22530.162109375,\n",
              " 31198.779296875,\n",
              " 30734.056640625,\n",
              " 34183.75390625,\n",
              " 26671.29296875,\n",
              " 27761.4765625,\n",
              " 25206.53125,\n",
              " 22707.427734375,\n",
              " 31824.560546875,\n",
              " 24829.046875,\n",
              " 28786.146484375,\n",
              " 21097.8203125,\n",
              " 20749.224609375,\n",
              " 27986.931640625,\n",
              " 30086.767578125,\n",
              " 33826.8203125,\n",
              " 33099.0,\n",
              " 30571.56640625,\n",
              " 32742.818359375,\n",
              " 32135.875,\n",
              " 28274.115234375,\n",
              " 26033.990234375,\n",
              " 28104.18359375,\n",
              " 28496.58984375,\n",
              " 29735.6484375,\n",
              " 26380.39453125,\n",
              " 29919.271484375,\n",
              " 31913.671875,\n",
              " 26881.55078125,\n",
              " 33262.34375,\n",
              " 29556.484375,\n",
              " 35481.921875,\n",
              " 25511.951171875,\n",
              " 32431.00390625,\n",
              " 33852.38671875,\n",
              " 38929.46875,\n",
              " 29152.033203125,\n",
              " 29511.07421875,\n",
              " 28935.615234375,\n",
              " 30343.4765625,\n",
              " 31242.41015625,\n",
              " 21633.53515625,\n",
              " 24112.48828125,\n",
              " 31723.630859375,\n",
              " 24691.83203125,\n",
              " 23542.369140625,\n",
              " 27068.6953125,\n",
              " 24914.7109375,\n",
              " 32449.45703125,\n",
              " 29416.78515625,\n",
              " 25563.5078125,\n",
              " 25096.703125,\n",
              " 25043.669921875,\n",
              " 24033.12890625,\n",
              " 28277.35546875,\n",
              " 31996.611328125,\n",
              " 34768.6015625,\n",
              " 34191.32421875,\n",
              " 32309.26953125,\n",
              " 31663.87109375,\n",
              " 32644.58984375,\n",
              " 32126.216796875,\n",
              " 34383.953125,\n",
              " 26229.62109375,\n",
              " 30615.625,\n",
              " 24305.61328125,\n",
              " 33732.46875,\n",
              " 32963.1015625,\n",
              " 29025.181640625,\n",
              " 35289.21875,\n",
              " 40452.65625,\n",
              " 32694.865234375,\n",
              " 30108.638671875,\n",
              " 40096.6796875,\n",
              " 32030.927734375,\n",
              " 35165.89453125,\n",
              " 24563.416015625,\n",
              " 32571.796875,\n",
              " 19935.37109375,\n",
              " 30928.859375,\n",
              " 27477.771484375,\n",
              " 22721.41796875,\n",
              " 33253.95703125,\n",
              " 36448.4765625,\n",
              " 28632.48046875,\n",
              " 36430.16796875,\n",
              " 42319.484375,\n",
              " 29269.75390625,\n",
              " 18594.615234375,\n",
              " 17521.4765625,\n",
              " 30708.595703125,\n",
              " 22889.6953125,\n",
              " 25739.189453125,\n",
              " 16206.8818359375,\n",
              " 27742.201171875,\n",
              " 24293.8359375,\n",
              " 22406.796875,\n",
              " 33861.3203125,\n",
              " 34038.2890625,\n",
              " 24684.357421875,\n",
              " 29844.6015625,\n",
              " 25797.04296875,\n",
              " 31207.9296875,\n",
              " 31846.8828125,\n",
              " 33358.078125,\n",
              " 28635.087890625,\n",
              " 26358.126953125,\n",
              " 31802.44140625,\n",
              " 32335.05859375,\n",
              " 31245.482421875,\n",
              " 30996.73828125,\n",
              " 21387.560546875,\n",
              " 29602.654296875,\n",
              " 15798.056640625,\n",
              " 21174.87109375,\n",
              " 25805.259765625,\n",
              " 30226.1875,\n",
              " 37790.42578125,\n",
              " 26937.125,\n",
              " 26693.63671875,\n",
              " 28925.2734375,\n",
              " 19659.623046875,\n",
              " 23151.0078125,\n",
              " 28778.30859375,\n",
              " 23832.4453125,\n",
              " 31996.123046875,\n",
              " 29437.46875,\n",
              " 29040.9375,\n",
              " 29419.6796875,\n",
              " 23895.173828125,\n",
              " 28150.65625,\n",
              " 30084.96875,\n",
              " 34661.20703125,\n",
              " 35619.515625,\n",
              " 34936.078125,\n",
              " 29677.9375,\n",
              " 29267.51171875,\n",
              " 22464.67578125,\n",
              " 29733.51171875,\n",
              " 29016.755859375,\n",
              " 31538.3203125,\n",
              " 24848.041015625,\n",
              " 25797.97265625,\n",
              " 21753.701171875,\n",
              " 24522.53125,\n",
              " 35288.2265625,\n",
              " 32861.96875,\n",
              " 24081.47265625,\n",
              " 25288.33984375,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(test_loss)\n",
        "plt.xlabel('Iterations of gradient descent')\n",
        "plt.ylabel('L2 loss')\n",
        "plt.title('Loss for test data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dtd4ymkVafCh"
      },
      "id": "dtd4ymkVafCh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('training accuracy is {}'.format(train_acc))\n",
        "print('test accuracy is {}'.format(test_acc))"
      ],
      "metadata": {
        "id": "9TM45DtCbi99"
      },
      "id": "9TM45DtCbi99",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bVtcGONpWq0Z"
      },
      "id": "bVtcGONpWq0Z"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "YOLO",
      "language": "python",
      "name": "yolo"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}