{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3485813",
   "metadata": {},
   "source": [
    "0. This notebook is the continuation to the preprocessing.ipynb notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60fcc27",
   "metadata": {},
   "source": [
    "1. Import all neccessary modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73af1d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bab0d03",
   "metadata": {},
   "source": [
    "2. Import X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e61570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad8a25",
   "metadata": {},
   "source": [
    "Code that loads the preprocessed npy arrays from the kosti dataset, extract frames and mscoco rows. Save for processing! This array contains all 3 variables at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06af4849",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr = np.load('/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/kosti/npyfiles/emotic_pre/train_cont_arr.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71dbbc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/kosti/mat2csv/emotic_pre/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46d52df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train.index[train['Folder']=='mscoco/images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "274e52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_idx = np.flatnonzero(train['Folder']=='mscoco/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f624a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_idx = np.flatnonzero(train['Folder']=='framesdb/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a4b36817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14276,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "639a39d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_np = train_arr[np_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33745b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_frames = train_arr[frames_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4c157b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = np.concatenate((t_np,t_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa84c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/train_con', train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fa6b227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load('/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/train_con.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f3edd15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.numeric.Int64Index"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0e7f7b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_arr[0] == y_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d6cb077b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[5, 3, 9]'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99428f03",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m arousal \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/kosti/npyfiles/emotic_pre/train_cont_arr.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:547\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:636\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1965\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "arousal = pd.read_csv('/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/All_ratings_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd70573",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.iloc[:,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5807af75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5, 3, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[6, 4, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7, 8, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[8, 9, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[7, 9, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21619</th>\n",
       "      <td>[6, 6, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21620</th>\n",
       "      <td>[5, 7, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21621</th>\n",
       "      <td>[5, 4, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21622</th>\n",
       "      <td>[6, 7, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21623</th>\n",
       "      <td>[5, 5, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21624 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0       [5, 3, 9]\n",
       "1       [6, 4, 7]\n",
       "2       [7, 8, 8]\n",
       "3       [8, 9, 8]\n",
       "4      [7, 9, 10]\n",
       "...           ...\n",
       "21619   [6, 6, 6]\n",
       "21620   [5, 7, 4]\n",
       "21621   [5, 4, 6]\n",
       "21622   [6, 7, 6]\n",
       "21623   [5, 5, 6]\n",
       "\n",
       "[21624 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "986e4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_8000_rows = y[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f1e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arr = y_8000_rows.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b76d8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f700efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf7012a",
   "metadata": {},
   "source": [
    "NEW APPROACH:\n",
    "\n",
    "Fit CNN on X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc2364",
   "metadata": {},
   "source": [
    "1. Read `n-rows`from X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27e2352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/10 chunks\n",
      "Processed 2/10 chunks\n",
      "Processed 3/10 chunks\n",
      "Processed 4/10 chunks\n",
      "Processed 5/10 chunks\n",
      "Processed 6/10 chunks\n",
      "Processed 7/10 chunks\n",
      "Processed 8/10 chunks\n",
      "Processed 9/10 chunks\n",
      "Processed 10/10 chunks\n"
     ]
    }
   ],
   "source": [
    "chunk = 10\n",
    "i=0\n",
    "X=[]\n",
    "import pandas as pd\n",
    "for df in pd.read_csv('X_matrix.csv',chunksize = chunk):\n",
    "    X.append(df)\n",
    "    i=i+1\n",
    "    print('Processed {i}/10 chunks'.format(i=i))\n",
    "    if i == 10:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deea97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6be9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X [X.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d148f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06126843",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr = np.reshape(X_arr,(100,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d763e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 224, 224)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd74af2",
   "metadata": {},
   "source": [
    "Adding new dimension for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f4c005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X_arr[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc2f2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.swapaxes(X_,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92fc96c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1, 224, 224)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c5e8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_,y_arr,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a16b405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100/3428171516.py:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train=np.vstack(y_train).astype(np.float)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[10, 6, 8]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_train\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m y_test\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mvstack(y_test)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[10, 6, 8]'"
     ]
    }
   ],
   "source": [
    "y_train=np.vstack(y_train).astype(np.float)\n",
    "y_test=np.vstack(y_test).astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc4d4d",
   "metadata": {},
   "source": [
    "Converting X to appropriate Datatype..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95e21cb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X_tensor_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X_train)\n\u001b[1;32m      2\u001b[0m X_tensor_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X_test)\n\u001b[0;32m----> 3\u001b[0m y_tensor_train \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m y_tensor_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_test)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "X_tensor_train = torch.from_numpy(X_train)\n",
    "X_tensor_test = torch.from_numpy(X_test)\n",
    "y_tensor_train = torch.from_numpy(y_train)\n",
    "y_tensor_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83ce427f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_142/3712994864.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor_train = torch.tensor(X_tensor_train,dtype = torch.float32)\n",
      "/tmp/ipykernel_142/3712994864.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor_test = torch.tensor(X_tensor_test,dtype = torch.float32)\n"
     ]
    }
   ],
   "source": [
    "X_tensor_train = torch.tensor(X_tensor_train,dtype = torch.float32)\n",
    "X_tensor_test = torch.tensor(X_tensor_test,dtype = torch.float32)\n",
    "y_tensor_train = y_tensor_train.type(torch.LongTensor)\n",
    "y_tensor_test = y_tensor_test.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e920b8",
   "metadata": {},
   "source": [
    "Pytorch needs the true labels to be in the range N-1. Thus, substract 1 one from each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe7f344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor_train = y_tensor_train-1\n",
    "y_tensor_test = y_tensor_test-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a467d280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape X is torch.Size([80, 1, 224, 224]), test shape X istorch.Size([20, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print('training shape X is {}, test shape X is{}'.format(X_tensor_train.shape,X_tensor_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379ae48",
   "metadata": {},
   "source": [
    "Setup custom dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c58277e",
   "metadata": {},
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,X_path, y_path):#, y_path):\n",
    "        df_x = pd.read_csv(X_path)\n",
    "        df_y = pd.read_csv(y_path)#'/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/Arousal.csv')\n",
    "        del X [X.columns[0]]\n",
    "        X = X.to_numpy()\n",
    "        X = np.reshape(X,(100,224,224))\n",
    "        X = X[:,:,np.newaxis]\n",
    "        X = np.swapaxes(X,2,1)\n",
    "        y = df_y.iloc[:,[1]]\n",
    "        \n",
    "        self.X_train = X\n",
    "        self.y_train = y.to_numpy()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y_train)#X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X_train = self.X[idx]\n",
    "        y_train= self.y_train[idx]\n",
    "        return X_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76e13d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81e0552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af6a5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = SimpleDataset(X_tensor_train,y_tensor_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "\n",
    "dataset_test = SimpleDataset(X_tensor_test,y_tensor_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size = 32,shuffle=True)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a8da2",
   "metadata": {},
   "source": [
    "dataset = CustomDataset('/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/X_matrix.csv','/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/Arousal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889205b9",
   "metadata": {},
   "source": [
    "dataset = CustomDataset(X_path ='/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/X_matrix.csv', y_path='/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/Arousal.csv')\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4df5ea",
   "metadata": {},
   "source": [
    "Setting up the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5b23ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.fc1 = nn.Linear(774400, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad94c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "SalienceNet = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9997283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(net, loss_fn, dataloader_train,dataloader_test,\n",
    "          epoch=100, learning_rate=0.01):\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)#,weight_decay=1e-4)\n",
    "    train_loss = []\n",
    "    acc=[]\n",
    "    for i in range(epoch):   \n",
    "        net.train()\n",
    "        correct, total = 0, 0\n",
    "        loss_count = 0\n",
    "        for data, label in dataloader_train:\n",
    "            data, label = data.to('cpu'), label.to('cpu')\n",
    "        #make prediction\n",
    "            output = net(data)\n",
    "\n",
    "            # Zero out the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calculate loss.\n",
    "            loss = criterion(output,torch.max(label, 1)[0])\n",
    "\n",
    "            # Backpropagation and gradient update.\n",
    "            loss.backward()# Calculate gradients. #retrain_graph=True\n",
    "\n",
    "            optimizer.step() # Apply gradient udpate.\n",
    "\n",
    "            loss_count += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            print(predicted, torch.max(label,1)[0])\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == torch.max(label,1)[0]).sum().item()\n",
    "          #  if (i + 1) % (epoch // 5) == 0:\n",
    "           #     print(f'iteration {i + 1}/{epoch} | loss: {loss.item():.3f}')\n",
    "    acc.append(correct/total)\n",
    "    train_loss.append(loss_count/len(dataloader_train))\n",
    "    \n",
    "    net.eval()\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    correct_test, total_test = 0,0\n",
    "    for data, labels in dataloader_test:\n",
    "        data, labels = data.to('cpu'), labels.to('cpu')\n",
    "        \n",
    "        outputs = net(data)\n",
    "        _, pred_test = torch.max(outputs,1)\n",
    "        total_test += labels.size(0)\n",
    "        print(total_test)\n",
    "        correct_test += (pred_test == torch.max(labels,1)[0]).sum().item()\n",
    "        print(correct_test)\n",
    "        test_l = criterion(outputs,torch.max(labels, 1)[0])\n",
    "        test_loss.append(test_l.item())\n",
    "    test_acc.append(correct_test/total_test)\n",
    "    print(acc,test_acc)\n",
    "    return acc,total,correct,train_loss,test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e318c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5ddd06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "3\n",
      "[0.175] [0.15]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "acc,total,correct,train_loss,test_acc=analysis(net=SalienceNet,loss_fn=criterion,dataloader_train=dataloader_train,\n",
    "                  dataloader_test=dataloader_test,epoch=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de6af6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.505991776784261]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "399e8794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=[]\n",
    "\n",
    "i.append(6/3)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "06f39808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4]) tensor([[5, 6, 3, 5, 6, 5, 5, 5, 5, 5, 5, 1, 4, 6, 6, 4, 5, 4, 4, 3, 6, 4, 6, 6,\n",
      "         5, 5, 4, 3, 4, 5, 4, 4]])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4]) tensor([[6, 5, 4, 3, 6, 7, 4, 4, 4, 5, 5, 9, 6, 7, 5, 4, 6, 6, 6, 6, 6, 7, 2, 5,\n",
      "         6, 6, 7, 5, 4, 7, 5, 6]])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]) tensor([[4, 1, 5, 6, 3, 5, 6, 7, 5, 6, 5, 2, 4, 5, 5, 5]])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4]) tensor([[6, 5, 5, 5, 5, 3, 7, 3, 5, 4, 6, 5, 3, 5, 5, 7, 4, 9, 6, 7, 3, 4, 6, 5,\n",
      "         1, 7, 5, 6, 5, 4, 4, 5]])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4]) tensor([[6, 6, 5, 6, 6, 4, 5, 7, 7, 5, 6, 5, 4, 4, 6, 1, 4, 5, 6, 5, 6, 6, 2, 5,\n",
      "         3, 4, 5, 6, 6, 6, 5, 4]])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]) tensor([[4, 4, 6, 4, 5, 6, 6, 5, 5, 4, 5, 5, 4, 4, 6, 2]])\n",
      "[0.2125]\n"
     ]
    }
   ],
   "source": [
    "total,correct = 0,0\n",
    "i=0\n",
    "loss = []\n",
    "while i < 5:\n",
    "    for x,y in dataloader_train:\n",
    "        output = SalienceNet(x)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        #predicted = torch.tensor()\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == torch.max(y,1)[0]).sum().item()\n",
    "        print(predicted,torch.transpose(y,1,0))\n",
    "        y_I = torch.max(y,1)[0]\n",
    "        i=i+1\n",
    "loss.append(correct/total)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6eb841cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1476, 0.1476, 0.1476, 0.1476, 0.1476, 0.1476, 0.1476, 0.1476, 0.1476,\n",
       "         0.1476, 0.1476, 0.1476, 0.1476, 0.1476, 0.1476, 0.1476],\n",
       "        grad_fn=<MaxBackward0>),\n",
       " tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1cd789d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 6, 4, 5, 6, 6, 5, 5, 4, 5, 5, 4, 4, 6, 2])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6159d77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "321633bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-65.9044,  44.7948, -50.0664,  22.9917,  63.5114, -65.3450,  30.7097,\n",
       "         130.8091, -44.3176,   9.8188],\n",
       "        [-66.7599,  45.2335, -50.6327,  23.2442,  64.3278, -66.1742,  31.0289,\n",
       "         132.4245, -45.0380,   9.9740],\n",
       "        [-67.2260,  45.4627, -50.9415,  23.4104,  64.8238, -66.7101,  31.0802,\n",
       "         133.4065, -45.5668,  10.1352],\n",
       "        [-66.6873,  45.1616, -50.5517,  23.2404,  64.2822, -66.0941,  30.9580,\n",
       "         132.2808, -45.0118,  10.0283],\n",
       "        [-66.2129,  44.9116, -50.2500,  23.0817,  63.8136, -65.5273,  30.9220,\n",
       "         131.2758, -44.4338,   9.8651],\n",
       "        [-67.0469,  45.4192, -50.8229,  23.3484,  64.6289, -66.5578,  31.0135,\n",
       "         133.0656, -45.3902,  10.1040],\n",
       "        [-66.3755,  45.0062, -50.3480,  23.1280,  63.9697, -65.7896,  30.8553,\n",
       "         131.6962, -44.7400,   9.9400],\n",
       "        [-67.0683,  45.3656, -50.8393,  23.3909,  64.6840, -66.6029,  30.9773,\n",
       "         133.1539, -45.5212,  10.1378],\n",
       "        [-66.3048,  44.9367, -50.3148,  23.1251,  63.9163, -65.6587,  30.9022,\n",
       "         131.5043, -44.6069,   9.9118],\n",
       "        [-66.6255,  45.1469, -50.5169,  23.2180,  64.2254, -66.0508,  30.9328,\n",
       "         132.1812, -44.9652,  10.0069],\n",
       "        [-66.6643,  45.1828, -50.6185,  23.2927,  64.3034, -66.1982,  30.8940,\n",
       "         132.3729, -45.0957,  10.0280],\n",
       "        [-67.2644,  45.5042, -51.0042,  23.4487,  64.8722, -66.7753,  31.1099,\n",
       "         133.4649, -45.5439,  10.1510],\n",
       "        [-66.3884,  44.9689, -50.3792,  23.1533,  63.9987, -65.6607,  31.0391,\n",
       "         131.5703, -44.5447,   9.8848],\n",
       "        [-66.3634,  45.0203, -50.3458,  23.1311,  63.9498, -65.7664,  30.8708,\n",
       "         131.6665, -44.6943,   9.9345],\n",
       "        [-66.6779,  45.2255, -50.6412,  23.2722,  64.3085, -66.2352,  30.8974,\n",
       "         132.4176, -45.1026,   9.9870],\n",
       "        [-66.7599,  45.2335, -50.6327,  23.2442,  64.3278, -66.1742,  31.0289,\n",
       "         132.4245, -45.0380,   9.9740]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6489938",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7776d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e94773",
   "metadata": {},
   "outputs": [],
   "source": [
    "5/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9257bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (x,y) in enumerate(dataloader_train):\n",
    "    print(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc,total,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc390c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.xlabel('Iterations of gradient descent')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLO",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
