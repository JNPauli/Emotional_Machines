{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3485813",
   "metadata": {},
   "source": [
    "0. This notebook is the continuation to the preprocessing.ipynb notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60fcc27",
   "metadata": {},
   "source": [
    "1. Import all neccessary modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73af1d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bab0d03",
   "metadata": {},
   "source": [
    "2. Import X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e61570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1acf72e",
   "metadata": {},
   "source": [
    "Code that loads the preprocessed npy arrays from the kosti dataset, extract frames and mscoco rows. Save for processing! This array contains all 3 variables at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1bd70573",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load('/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/train_con.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5807af75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 9],\n",
       "       [6, 4, 7],\n",
       "       [7, 8, 8],\n",
       "       ...,\n",
       "       [5, 4, 6],\n",
       "       [6, 7, 6],\n",
       "       [5, 5, 6]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "986e4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = y[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2d1f9619",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_frames = y[14276:14376]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f9aa8768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 3), (100, 3))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.shape, y_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "31daef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = np.concatenate((y_,y_frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf7012a",
   "metadata": {},
   "source": [
    "NEW APPROACH:\n",
    "\n",
    "Fit CNN on X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc2364",
   "metadata": {},
   "source": [
    "1. Read `n-rows`from X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "27e2352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/X_npy.npy')\n",
    "frames = np.load('/mnt/c/Users/janos/OneDrive/Desktop/Master_thesis/frames_npy.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3d763e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_100 = X[0:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "eba94b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_100 = frames[0:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "23f5e4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 1, 224, 224), (100, 1, 224, 224))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_100.shape, frames_100.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1d7fff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_con = np.concatenate((X_100,frames_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "603a243e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 1, 224, 224), (200, 3))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_con.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9c5e8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_con,y_all,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc4d4d",
   "metadata": {},
   "source": [
    "Converting X to appropriate Datatype..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "95e21cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor_train = torch.from_numpy(X_train)\n",
    "X_tensor_test = torch.from_numpy(X_test)\n",
    "y_tensor_train = torch.from_numpy(y_train)\n",
    "y_tensor_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "83ce427f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100/3712994864.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor_train = torch.tensor(X_tensor_train,dtype = torch.float32)\n",
      "/tmp/ipykernel_100/3712994864.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor_test = torch.tensor(X_tensor_test,dtype = torch.float32)\n"
     ]
    }
   ],
   "source": [
    "X_tensor_train = torch.tensor(X_tensor_train,dtype = torch.float32)\n",
    "X_tensor_test = torch.tensor(X_tensor_test,dtype = torch.float32)\n",
    "y_tensor_train = y_tensor_train.type(torch.LongTensor)\n",
    "y_tensor_test = y_tensor_test.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e920b8",
   "metadata": {},
   "source": [
    "Pytorch needs the true labels to be in the range N-1. Thus, substract 1 one from each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fe7f344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor_train = y_tensor_train-1\n",
    "y_tensor_test = y_tensor_test-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a467d280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape X is torch.Size([160, 1, 224, 224]), test shape X istorch.Size([40, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print('training shape X is {}, test shape X is{}'.format(X_tensor_train.shape,X_tensor_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379ae48",
   "metadata": {},
   "source": [
    "Setup custom dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "76e13d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "81e0552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "af6a5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = SimpleDataset(X_tensor_train,y_tensor_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "\n",
    "dataset_test = SimpleDataset(X_tensor_test,y_tensor_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size = 32,shuffle=True)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4df5ea",
   "metadata": {},
   "source": [
    "Setting up the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c5b23ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.fc1 = nn.Linear(774400, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ad94c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "SalienceNet = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9997283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(net, loss_fn, dataloader_train,dataloader_test,\n",
    "          epoch=100, learning_rate=0.01):\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)#,weight_decay=1e-4)\n",
    "    train_loss = []\n",
    "    acc=[]\n",
    "    for i in range(epoch):   \n",
    "        net.train()\n",
    "        correct, total = 0, 0\n",
    "        loss_count = 0\n",
    "        for data, label in dataloader_train:\n",
    "            data, label = data.to('cpu'), label.to('cpu')\n",
    "        #make prediction\n",
    "            output = net(data)\n",
    "\n",
    "            # Zero out the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calculate loss.\n",
    "            loss = criterion(output,label)#torch.max(label, 1)[0])\n",
    "\n",
    "            # Backpropagation and gradient update.\n",
    "            loss.backward()# Calculate gradients. #retrain_graph=True\n",
    "\n",
    "            optimizer.step() # Apply gradient udpate.\n",
    "\n",
    "            loss_count += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            print(predicted, torch.max(label,1)[0])\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == torch.max(label,1)[0]).sum().item()\n",
    "          #  if (i + 1) % (epoch // 5) == 0:\n",
    "           #     print(f'iteration {i + 1}/{epoch} | loss: {loss.item():.3f}')\n",
    "    acc.append(correct/total)\n",
    "    train_loss.append(loss_count/len(dataloader_train))\n",
    "    \n",
    "    net.eval()\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    correct_test, total_test = 0,0\n",
    "    for data, labels in dataloader_test:\n",
    "        data, labels = data.to('cpu'), labels.to('cpu')\n",
    "        \n",
    "        outputs = net(data)\n",
    "        _, pred_test = torch.max(outputs,1)\n",
    "        total_test += labels.size(0)\n",
    "        print(total_test)\n",
    "        correct_test += (pred_test == torch.max(labels,1)[0]).sum().item()\n",
    "        print(correct_test)\n",
    "        test_l = criterion(outputs,torch.max(labels, 1)[0])\n",
    "        test_loss.append(test_l.item())\n",
    "    test_acc.append(correct_test/total_test)\n",
    "    print(acc,test_acc)\n",
    "    return acc,total,correct,train_loss,test_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4fc285",
   "metadata": {},
   "source": [
    "EMOTIC LOSS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9e2fcd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousLoss_L2(nn.Module):\n",
    "  ''' Class to measure loss between continuous emotion dimension predictions and labels. Using l2 loss as base. '''\n",
    "  def __init__(self, margin=1):\n",
    "    super(ContinuousLoss_L2, self).__init__()\n",
    "    self.margin = margin\n",
    "  \n",
    "  def forward(self, pred, target):\n",
    "    labs = torch.abs(pred - target)\n",
    "    loss = labs ** 2 \n",
    "    loss[ (labs < self.margin) ] = 0.0\n",
    "    return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7e318c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8dde6e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i=0\n",
    "#while i < 1:\n",
    " #   for x,y in dataloader_train:\n",
    "  #      out=SalienceNet(x)\n",
    "   #     loss = criterion(out,y.float())\n",
    "    #    print(loss, out, y)\n",
    "     #   i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ff555053",
   "metadata": {},
   "outputs": [],
   "source": [
    "testtest=X_tensor_train[0:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "23b145e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 224, 224])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "85dfaba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0053,  0.0434, -0.0565]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = SalienceNet(testtest)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7b42798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_loss = ContinuousLoss_L2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "db35f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_loss_batch = cont_loss(out * 10, y_tensor_train[0:1,:] * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "201e610c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0526,  0.4338, -0.5647]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5c598023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8607.2871, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_loss_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "678717f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(out,y_tensor_train[0:1,:].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "68efefa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.5834, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2e2457f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d4714860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0434], grad_fn=<MaxBackward0>), tensor([1]))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c5ddd06d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 6 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[184], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m acc,total,correct,train_loss,test_acc\u001b[38;5;241m=\u001b[39m\u001b[43manalysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSalienceNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mdataloader_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[182], line 19\u001b[0m, in \u001b[0;36manalysis\u001b[0;34m(net, loss_fn, dataloader_train, dataloader_test, epoch, learning_rate)\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate loss.\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Backpropagation and gradient update.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\u001b[38;5;66;03m# Calculate gradients. #retrain_graph=True\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo/lib/python3.10/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 6 is out of bounds."
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "acc,total,correct,train_loss,test_acc=analysis(net=SalienceNet,loss_fn=criterion,dataloader_train=dataloader_train,\n",
    "                  dataloader_test=dataloader_test,epoch=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de6af6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.505991776784261]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "399e8794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=[]\n",
    "\n",
    "i.append(6/3)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "06f39808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4]) tensor([[5, 6, 3, 5, 6, 5, 5, 5, 5, 5, 5, 1, 4, 6, 6, 4, 5, 4, 4, 3, 6, 4, 6, 6,\n",
      "         5, 5, 4, 3, 4, 5, 4, 4]])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4]) tensor([[6, 5, 4, 3, 6, 7, 4, 4, 4, 5, 5, 9, 6, 7, 5, 4, 6, 6, 6, 6, 6, 7, 2, 5,\n",
      "         6, 6, 7, 5, 4, 7, 5, 6]])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]) tensor([[4, 1, 5, 6, 3, 5, 6, 7, 5, 6, 5, 2, 4, 5, 5, 5]])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4]) tensor([[6, 5, 5, 5, 5, 3, 7, 3, 5, 4, 6, 5, 3, 5, 5, 7, 4, 9, 6, 7, 3, 4, 6, 5,\n",
      "         1, 7, 5, 6, 5, 4, 4, 5]])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4]) tensor([[6, 6, 5, 6, 6, 4, 5, 7, 7, 5, 6, 5, 4, 4, 6, 1, 4, 5, 6, 5, 6, 6, 2, 5,\n",
      "         3, 4, 5, 6, 6, 6, 5, 4]])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]) tensor([[4, 4, 6, 4, 5, 6, 6, 5, 5, 4, 5, 5, 4, 4, 6, 2]])\n",
      "[0.2125]\n"
     ]
    }
   ],
   "source": [
    "total,correct = 0,0\n",
    "i=0\n",
    "loss = []\n",
    "while i < 5:\n",
    "    for x,y in dataloader_train:\n",
    "        output = SalienceNet(x)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        #predicted = torch.tensor()\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == torch.max(y,1)[0]).sum().item()\n",
    "        print(predicted,torch.transpose(y,1,0))\n",
    "        y_I = torch.max(y,1)[0]\n",
    "        i=i+1\n",
    "loss.append(correct/total)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6eb841cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1476, 0.1476, 0.1476, 0.1476, 0.1476, 0.1476, 0.1476, 0.1476, 0.1476,\n",
       "         0.1476, 0.1476, 0.1476, 0.1476, 0.1476, 0.1476, 0.1476],\n",
       "        grad_fn=<MaxBackward0>),\n",
       " tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1cd789d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 6, 4, 5, 6, 6, 5, 5, 4, 5, 5, 4, 4, 6, 2])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6159d77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "321633bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-65.9044,  44.7948, -50.0664,  22.9917,  63.5114, -65.3450,  30.7097,\n",
       "         130.8091, -44.3176,   9.8188],\n",
       "        [-66.7599,  45.2335, -50.6327,  23.2442,  64.3278, -66.1742,  31.0289,\n",
       "         132.4245, -45.0380,   9.9740],\n",
       "        [-67.2260,  45.4627, -50.9415,  23.4104,  64.8238, -66.7101,  31.0802,\n",
       "         133.4065, -45.5668,  10.1352],\n",
       "        [-66.6873,  45.1616, -50.5517,  23.2404,  64.2822, -66.0941,  30.9580,\n",
       "         132.2808, -45.0118,  10.0283],\n",
       "        [-66.2129,  44.9116, -50.2500,  23.0817,  63.8136, -65.5273,  30.9220,\n",
       "         131.2758, -44.4338,   9.8651],\n",
       "        [-67.0469,  45.4192, -50.8229,  23.3484,  64.6289, -66.5578,  31.0135,\n",
       "         133.0656, -45.3902,  10.1040],\n",
       "        [-66.3755,  45.0062, -50.3480,  23.1280,  63.9697, -65.7896,  30.8553,\n",
       "         131.6962, -44.7400,   9.9400],\n",
       "        [-67.0683,  45.3656, -50.8393,  23.3909,  64.6840, -66.6029,  30.9773,\n",
       "         133.1539, -45.5212,  10.1378],\n",
       "        [-66.3048,  44.9367, -50.3148,  23.1251,  63.9163, -65.6587,  30.9022,\n",
       "         131.5043, -44.6069,   9.9118],\n",
       "        [-66.6255,  45.1469, -50.5169,  23.2180,  64.2254, -66.0508,  30.9328,\n",
       "         132.1812, -44.9652,  10.0069],\n",
       "        [-66.6643,  45.1828, -50.6185,  23.2927,  64.3034, -66.1982,  30.8940,\n",
       "         132.3729, -45.0957,  10.0280],\n",
       "        [-67.2644,  45.5042, -51.0042,  23.4487,  64.8722, -66.7753,  31.1099,\n",
       "         133.4649, -45.5439,  10.1510],\n",
       "        [-66.3884,  44.9689, -50.3792,  23.1533,  63.9987, -65.6607,  31.0391,\n",
       "         131.5703, -44.5447,   9.8848],\n",
       "        [-66.3634,  45.0203, -50.3458,  23.1311,  63.9498, -65.7664,  30.8708,\n",
       "         131.6665, -44.6943,   9.9345],\n",
       "        [-66.6779,  45.2255, -50.6412,  23.2722,  64.3085, -66.2352,  30.8974,\n",
       "         132.4176, -45.1026,   9.9870],\n",
       "        [-66.7599,  45.2335, -50.6327,  23.2442,  64.3278, -66.1742,  31.0289,\n",
       "         132.4245, -45.0380,   9.9740]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6489938",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7776d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e94773",
   "metadata": {},
   "outputs": [],
   "source": [
    "5/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9257bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (x,y) in enumerate(dataloader_train):\n",
    "    print(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc,total,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc390c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.xlabel('Iterations of gradient descent')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLO",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
